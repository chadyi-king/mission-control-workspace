{"text": " Okay, so once again, you are saying that you don't, I don't need to manually do anything. But every time I have to, after I send a voice message, I have to say, okay, reply, because you're saying that you're transcribing the latest voice message. But the moment I say, okay, reply, you actually transcribe it very, very quickly. Yeah, which is after you transcribe it, then you already prompt me back, right? So with this, this is the conversation I'm having. So right now I'm seeing that the current issue is that I send a message, you say you're transcribing, but you don't automatically reply me. So I have to prompt you almost immediately and actually you do it quite fast. So then that's where my issue is. Can you create a way that after I send you the voice message, then you tell me or you're transcribing blah, blah, blah, but then you prompt yourself again to reply me? Because that's not happening and that's the issue.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.76, "text": " Okay, so once again, you are saying that you don't, I don't need to manually do anything.", "tokens": [50364, 1033, 11, 370, 1564, 797, 11, 291, 366, 1566, 300, 291, 500, 380, 11, 286, 500, 380, 643, 281, 16945, 360, 1340, 13, 50802], "temperature": 0.0, "avg_logprob": -0.20124644470214845, "compression_ratio": 1.79296875, "no_speech_prob": 0.2073928564786911}, {"id": 1, "seek": 0, "start": 8.76, "end": 14.08, "text": " But every time I have to, after I send a voice message, I have to say, okay, reply, because", "tokens": [50802, 583, 633, 565, 286, 362, 281, 11, 934, 286, 2845, 257, 3177, 3636, 11, 286, 362, 281, 584, 11, 1392, 11, 16972, 11, 570, 51068], "temperature": 0.0, "avg_logprob": -0.20124644470214845, "compression_ratio": 1.79296875, "no_speech_prob": 0.2073928564786911}, {"id": 2, "seek": 0, "start": 14.08, "end": 17.48, "text": " you're saying that you're transcribing the latest voice message.", "tokens": [51068, 291, 434, 1566, 300, 291, 434, 1145, 39541, 264, 6792, 3177, 3636, 13, 51238], "temperature": 0.0, "avg_logprob": -0.20124644470214845, "compression_ratio": 1.79296875, "no_speech_prob": 0.2073928564786911}, {"id": 3, "seek": 0, "start": 17.48, "end": 21.44, "text": " But the moment I say, okay, reply, you actually transcribe it very, very quickly.", "tokens": [51238, 583, 264, 1623, 286, 584, 11, 1392, 11, 16972, 11, 291, 767, 1145, 8056, 309, 588, 11, 588, 2661, 13, 51436], "temperature": 0.0, "avg_logprob": -0.20124644470214845, "compression_ratio": 1.79296875, "no_speech_prob": 0.2073928564786911}, {"id": 4, "seek": 0, "start": 21.44, "end": 26.36, "text": " Yeah, which is after you transcribe it, then you already prompt me back, right?", "tokens": [51436, 865, 11, 597, 307, 934, 291, 1145, 8056, 309, 11, 550, 291, 1217, 12391, 385, 646, 11, 558, 30, 51682], "temperature": 0.0, "avg_logprob": -0.20124644470214845, "compression_ratio": 1.79296875, "no_speech_prob": 0.2073928564786911}, {"id": 5, "seek": 0, "start": 26.36, "end": 29.240000000000002, "text": " So with this, this is the conversation I'm having.", "tokens": [51682, 407, 365, 341, 11, 341, 307, 264, 3761, 286, 478, 1419, 13, 51826], "temperature": 0.0, "avg_logprob": -0.20124644470214845, "compression_ratio": 1.79296875, "no_speech_prob": 0.2073928564786911}, {"id": 6, "seek": 2924, "start": 29.24, "end": 36.239999999999995, "text": " So right now I'm seeing that the current issue is that I send a message, you say you're transcribing,", "tokens": [50364, 407, 558, 586, 286, 478, 2577, 300, 264, 2190, 2734, 307, 300, 286, 2845, 257, 3636, 11, 291, 584, 291, 434, 1145, 39541, 11, 50714], "temperature": 0.0, "avg_logprob": -0.1331611845228407, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.011842094361782074}, {"id": 7, "seek": 2924, "start": 36.239999999999995, "end": 39.8, "text": " but you don't automatically reply me.", "tokens": [50714, 457, 291, 500, 380, 6772, 16972, 385, 13, 50892], "temperature": 0.0, "avg_logprob": -0.1331611845228407, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.011842094361782074}, {"id": 8, "seek": 2924, "start": 39.8, "end": 45.94, "text": " So I have to prompt you almost immediately and actually you do it quite fast.", "tokens": [50892, 407, 286, 362, 281, 12391, 291, 1920, 4258, 293, 767, 291, 360, 309, 1596, 2370, 13, 51199], "temperature": 0.0, "avg_logprob": -0.1331611845228407, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.011842094361782074}, {"id": 9, "seek": 2924, "start": 45.94, "end": 47.8, "text": " So then that's where my issue is.", "tokens": [51199, 407, 550, 300, 311, 689, 452, 2734, 307, 13, 51292], "temperature": 0.0, "avg_logprob": -0.1331611845228407, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.011842094361782074}, {"id": 10, "seek": 2924, "start": 47.8, "end": 53.76, "text": " Can you create a way that after I send you the voice message, then you tell me or you're", "tokens": [51292, 1664, 291, 1884, 257, 636, 300, 934, 286, 2845, 291, 264, 3177, 3636, 11, 550, 291, 980, 385, 420, 291, 434, 51590], "temperature": 0.0, "avg_logprob": -0.1331611845228407, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.011842094361782074}, {"id": 11, "seek": 5376, "start": 53.76, "end": 60.08, "text": " transcribing blah, blah, blah, but then you prompt yourself again to reply me?", "tokens": [50364, 1145, 39541, 12288, 11, 12288, 11, 12288, 11, 457, 550, 291, 12391, 1803, 797, 281, 16972, 385, 30, 50680], "temperature": 0.0, "avg_logprob": -0.28237469056073355, "compression_ratio": 1.2772277227722773, "no_speech_prob": 0.3583647310733795}, {"id": 12, "seek": 5376, "start": 60.08, "end": 61.839999999999996, "text": " Because that's not happening and that's the issue.", "tokens": [50680, 1436, 300, 311, 406, 2737, 293, 300, 311, 264, 2734, 13, 50768], "temperature": 0.0, "avg_logprob": -0.28237469056073355, "compression_ratio": 1.2772277227722773, "no_speech_prob": 0.3583647310733795}], "language": "en"}